{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb84f2fd",
   "metadata": {},
   "source": [
    "# AutoGluon Tabular with Deep Learning Containers on SageMaker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a389c40c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/advanced_functionality|autogluon-tabular-containers|AutoGluon_Tabular_SageMaker_Containers.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "775e84ba",
   "metadata": {},
   "source": [
    "[AutoGluon](https://github.com/awslabs/autogluon) automates machine learning tasks enabling you to easily achieve strong predictive performance in your applications. With just a few lines of code, you can train and deploy high-accuracy deep learning models on tabular, image, and text data.\n",
    "This example shows how to use AutoGluon-Tabular with Amazon SageMaker by applying [pre-built deep learning containers](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#autogluon-training-containers)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4992c4f",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ea8f68a",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-26T09:52:39.035856Z",
     "start_time": "2024-03-26T09:52:39.027591Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Ensure autogluon the most recent images information is available in SageMaker Python SDK\n",
    "# !pip install -q -U 'sagemaker>=2.126.0'"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "path_root = \"/Users/elnath/004_deep_learning/SageMaker-Practical-Course\"\n",
    "conf = OmegaConf.load(f\"{path_root}/config_my.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T09:52:39.220409Z",
     "start_time": "2024-03-26T09:52:39.214645Z"
    }
   },
   "id": "74ebcbfcce044458",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "faf25796",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T09:52:40.082992Z",
     "start_time": "2024-03-26T09:52:39.396656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/elnath/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import pandas as pd\n",
    "from ag_model import (\n",
    "    AutoGluonSagemakerEstimator,\n",
    "    AutoGluonNonRepackInferenceModel,\n",
    "    AutoGluonSagemakerInferenceModel,\n",
    "    AutoGluonRealtimePredictor,\n",
    "    AutoGluonBatchPredictor,\n",
    ")\n",
    "from sagemaker import utils\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "import os\n",
    "import boto3\n",
    "\n",
    "# role = sagemaker.get_execution_role()\n",
    "role = conf.common.execution_role\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "region = sagemaker_session._region_name\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "s3_prefix = f\"autogluon_sm/{utils.sagemaker_timestamp()}\"\n",
    "output_path = f\"s3://{bucket}/{s3_prefix}/output/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c006dc0",
   "metadata": {},
   "source": [
    "### Get the data\n",
    "We'll be using the [Adult Census dataset](https://archive.ics.uci.edu/ml/datasets/adult) for this exercise. \n",
    "This data was extracted from the [1994 Census bureau database](http://www.census.gov/en.html) by Ronny Kohavi and Barry Becker (Data Mining and Visualization, Silicon Graphics), with the task being to predict if an individual person makes over 50K a year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d00074fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T09:52:40.250483Z",
     "start_time": "2024-03-26T09:52:40.081559Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a102722b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T09:52:40.252714Z",
     "start_time": "2024-03-26T09:52:40.232555Z"
    }
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"age\",\n",
    "    \"workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"education\",\n",
    "    \"education-num\",\n",
    "    \"marital-status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"capital-gain\",\n",
    "    \"capital-loss\",\n",
    "    \"hours-per-week\",\n",
    "    \"native-country\",\n",
    "    \"class\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f1218fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T09:52:40.993348Z",
     "start_time": "2024-03-26T09:52:40.241055Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download the data - needed for examples; in notebooks, S3 URL can be directly used for loading from S3\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.download_file(\n",
    "    f\"sagemaker-example-files-prod-{region}\",\n",
    "    \"datasets/tabular/uci_adult/adult.data\",\n",
    "    \"data/adult.data\",\n",
    ")\n",
    "s3.download_file(\n",
    "    f\"sagemaker-example-files-prod-{region}\",\n",
    "    \"datasets/tabular/uci_adult/adult.test\",\n",
    "    \"data/adult.test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c242a5f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T09:52:41.275888Z",
     "start_time": "2024-03-26T09:52:40.994211Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/adult.data\", header=None, names=columns)\n",
    "df_train.to_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f2888ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T09:52:41.372375Z",
     "start_time": "2024-03-26T09:52:41.247448Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"data/adult.test\", header=None, skiprows=1, names=columns)\n",
    "df_test[\"class\"] = df_test[\"class\"].map(\n",
    "    {\n",
    "        \" <=50K.\": \" <=50K\",\n",
    "        \" >50K.\": \" >50K\",\n",
    "    }\n",
    ")\n",
    "df_test.to_csv(\"data/test.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8213590f",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b453761",
   "metadata": {},
   "source": [
    "Users can create their own training/inference scripts using [SageMaker Python SDK examples](https://sagemaker.readthedocs.io/en/stable/overview.html#prepare-a-training-script).\n",
    "The scripts we created allow to pass AutoGluon configuration as a YAML file (located in `data/config` directory).\n",
    "\n",
    "We are using [official AutoGluon Deep Learning Container images](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#autogluon-training-containers) with custom training scripts (see `scripts/` directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da167200",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T09:52:41.455499Z",
     "start_time": "2024-03-26T09:52:41.371965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/elnath/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/elnath/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "ag = AutoGluonSagemakerEstimator(\n",
    "    role=role,\n",
    "    entry_point=\"scripts/tabular_train.py\",\n",
    "    region=region,\n",
    "    instance_count=1,\n",
    "    # instance_type=\"ml.m5.2xlarge\",\n",
    "    instance_type=\"local\",\n",
    "    # conda에서의 sagemeaker SDK 버전이 낮아 1.0 미지원\n",
    "    framework_version=\"0.8\",\n",
    "    py_version=\"py39\",\n",
    "    base_job_name=\"autogluon-tabular-train\",\n",
    "    disable_profiler=True,\n",
    "    debugger_hook_config=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69870f34",
   "metadata": {},
   "source": [
    "Upload the data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "204a60b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T09:52:42.937955Z",
     "start_time": "2024-03-26T09:52:41.421709Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "s3_prefix = f\"autogluon_sm/{utils.sagemaker_timestamp()}\"\n",
    "train_input = ag.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"data\", \"train.csv\"), key_prefix=s3_prefix\n",
    ")\n",
    "eval_input = ag.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"data\", \"test.csv\"), key_prefix=s3_prefix\n",
    ")\n",
    "config_input = ag.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"config\", \"config-med.yaml\"), key_prefix=s3_prefix\n",
    ")\n",
    "\n",
    "# Provide inference script so the script repacking is not needed later\n",
    "# See more here: https://docs.aws.amazon.com/sagemaker/latest/dg/mlopsfaq.html\n",
    "# Q. Why do I see a repack step in my SageMaker pipeline?\n",
    "inference_script = ag.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"scripts\", \"tabular_serve.py\"), key_prefix=s3_prefix\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fedb3195",
   "metadata": {},
   "source": [
    "### Fit The Model\n",
    "For local training set `instance_type` to local.\n",
    "\n",
    "For non-local training the recommended instance type is `ml.m5.2xlarge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "794ea738",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T10:05:16.020344Z",
     "start_time": "2024-03-26T09:52:42.922299Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: test-autogluon-image-1711446762-9abf\n",
      "INFO:sagemaker.local.image:'Docker Compose' found using Docker CLI.\n",
      "INFO:sagemaker.local.local_session:Starting training job\n",
      "INFO:sagemaker.local.image:Using the long-lived AWS credentials found in session\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-28c43:\n",
      "    command: train\n",
      "    container_name: u4na7hxy1w-algo-1-28c43\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: 763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/autogluon-training:0.8-cpu-py39\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-28c43\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/algo-1-28c43/input:/opt/ml/input\n",
      "    - /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/algo-1-28c43/output:/opt/ml/output\n",
      "    - /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/algo-1-28c43/output/data:/opt/ml/output/data\n",
      "    - /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model:/opt/ml/model\n",
      "    - /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmphhumkvot:/opt/ml/input/data/config\n",
      "    - /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpctd43xn1:/opt/ml/input/data/train\n",
      "    - /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpr1kfmenf:/opt/ml/input/data/test\n",
      "    - /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmp2yl63v7p:/opt/ml/input/data/serving\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker compose -f /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/docker-compose.yaml up --build --abort-on-container-exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time=\"2024-03-26T18:52:48+09:00\" level=warning msg=\"a network with name sagemaker-local exists but was not created for project \\\"tmpvwf859g4\\\".\\nSet `external: true` to use an existing network\"\n",
      " Container u4na7hxy1w-algo-1-28c43  Creating\n",
      " Container u4na7hxy1w-algo-1-28c43  Created\n",
      "Attaching to u4na7hxy1w-algo-1-28c43\n",
      "u4na7hxy1w-algo-1-28c43  | 2024-03-26 09:52:50,602 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2024-03-26 09:52:50,604 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2024-03-26 09:52:50,606 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2024-03-26 09:52:50,615 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2024-03-26 09:52:50,618 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2024-03-26 09:52:50,628 sagemaker_pytorch_container.training INFO     Invoking user training script.\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2024-03-26 09:52:50,793 botocore.credentials INFO     Found credentials in environment variables.\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2024-03-26 09:52:51,044 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2024-03-26 09:52:51,047 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2024-03-26 09:52:51,056 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2024-03-26 09:52:51,063 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2024-03-26 09:52:51,066 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2024-03-26 09:52:51,077 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2024-03-26 09:52:51,083 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2024-03-26 09:52:51,086 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2024-03-26 09:52:51,096 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2024-03-26 09:52:51,099 sagemaker-training-toolkit INFO     Invoking user script\r\n",
      "u4na7hxy1w-algo-1-28c43  | \r\n",
      "u4na7hxy1w-algo-1-28c43  | Training Env:\r\n",
      "u4na7hxy1w-algo-1-28c43  | \r\n",
      "u4na7hxy1w-algo-1-28c43  | {\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"additional_framework_parameters\": {},\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"channel_input_dirs\": {\r\n",
      "u4na7hxy1w-algo-1-28c43  |         \"config\": \"/opt/ml/input/data/config\",\r\n",
      "u4na7hxy1w-algo-1-28c43  |         \"train\": \"/opt/ml/input/data/train\",\r\n",
      "u4na7hxy1w-algo-1-28c43  |         \"test\": \"/opt/ml/input/data/test\",\r\n",
      "u4na7hxy1w-algo-1-28c43  |         \"serving\": \"/opt/ml/input/data/serving\"\r\n",
      "u4na7hxy1w-algo-1-28c43  |     },\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"current_host\": \"algo-1-28c43\",\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"current_instance_group\": \"homogeneousCluster\",\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"current_instance_group_hosts\": [],\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"current_instance_type\": \"local\",\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"distribution_hosts\": [\r\n",
      "u4na7hxy1w-algo-1-28c43  |         \"algo-1-28c43\"\r\n",
      "u4na7hxy1w-algo-1-28c43  |     ],\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"distribution_instance_groups\": [],\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"hosts\": [\r\n",
      "u4na7hxy1w-algo-1-28c43  |         \"algo-1-28c43\"\r\n",
      "u4na7hxy1w-algo-1-28c43  |     ],\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"hyperparameters\": {},\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"input_config_dir\": \"/opt/ml/input/config\",\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"input_data_config\": {\r\n",
      "u4na7hxy1w-algo-1-28c43  |         \"config\": {\r\n",
      "u4na7hxy1w-algo-1-28c43  |             \"TrainingInputMode\": \"File\"\r\n",
      "u4na7hxy1w-algo-1-28c43  |         },\r\n",
      "u4na7hxy1w-algo-1-28c43  |         \"train\": {\r\n",
      "u4na7hxy1w-algo-1-28c43  |             \"TrainingInputMode\": \"File\"\r\n",
      "u4na7hxy1w-algo-1-28c43  |         },\r\n",
      "u4na7hxy1w-algo-1-28c43  |         \"test\": {\r\n",
      "u4na7hxy1w-algo-1-28c43  |             \"TrainingInputMode\": \"File\"\r\n",
      "u4na7hxy1w-algo-1-28c43  |         },\r\n",
      "u4na7hxy1w-algo-1-28c43  |         \"serving\": {\r\n",
      "u4na7hxy1w-algo-1-28c43  |             \"TrainingInputMode\": \"File\"\r\n",
      "u4na7hxy1w-algo-1-28c43  |         }\r\n",
      "u4na7hxy1w-algo-1-28c43  |     },\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"input_dir\": \"/opt/ml/input\",\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"instance_groups\": [],\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"instance_groups_dict\": {},\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"is_hetero\": false,\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"is_master\": true,\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"is_modelparallel_enabled\": null,\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"is_smddpmprun_installed\": false,\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"job_name\": \"test-autogluon-image-1711446762-9abf\",\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"log_level\": 20,\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"master_hostname\": \"algo-1-28c43\",\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"model_dir\": \"/opt/ml/model\",\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"module_dir\": \"s3://sagemaker-ap-northeast-2-688554574862/test-autogluon-image-1711446762-9abf/source/sourcedir.tar.gz\",\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"module_name\": \"tabular_train\",\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"network_interface_name\": \"eth0\",\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"num_cpus\": 16,\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"num_gpus\": 0,\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"num_neurons\": 0,\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"output_data_dir\": \"/opt/ml/output/data\",\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"output_dir\": \"/opt/ml/output\",\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"resource_config\": {\r\n",
      "u4na7hxy1w-algo-1-28c43  |         \"current_host\": \"algo-1-28c43\",\r\n",
      "u4na7hxy1w-algo-1-28c43  |         \"hosts\": [\r\n",
      "u4na7hxy1w-algo-1-28c43  |             \"algo-1-28c43\"\r\n",
      "u4na7hxy1w-algo-1-28c43  |         ]\r\n",
      "u4na7hxy1w-algo-1-28c43  |     },\r\n",
      "u4na7hxy1w-algo-1-28c43  |     \"user_entry_point\": \"tabular_train.py\"\r\n",
      "u4na7hxy1w-algo-1-28c43  | }\r\n",
      "u4na7hxy1w-algo-1-28c43  | \r\n",
      "u4na7hxy1w-algo-1-28c43  | Environment variables:\r\n",
      "u4na7hxy1w-algo-1-28c43  | \r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_HOSTS=[\"algo-1-28c43\"]\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_NETWORK_INTERFACE_NAME=eth0\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_HPS={}\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_USER_ENTRY_POINT=tabular_train.py\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_FRAMEWORK_PARAMS={}\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-28c43\",\"hosts\":[\"algo-1-28c43\"]}\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_INPUT_DATA_CONFIG={\"config\":{\"TrainingInputMode\":\"File\"},\"serving\":{\"TrainingInputMode\":\"File\"},\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_OUTPUT_DATA_DIR=/opt/ml/output/data\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_CHANNELS=[\"config\",\"serving\",\"test\",\"train\"]\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_CURRENT_HOST=algo-1-28c43\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_CURRENT_INSTANCE_TYPE=local\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_CURRENT_INSTANCE_GROUP_HOSTS=[]\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_INSTANCE_GROUPS=[]\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_INSTANCE_GROUPS_DICT={}\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_DISTRIBUTION_INSTANCE_GROUPS=[]\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_IS_HETERO=false\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_MODULE_NAME=tabular_train\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_LOG_LEVEL=20\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_INPUT_DIR=/opt/ml/input\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_INPUT_CONFIG_DIR=/opt/ml/input/config\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_OUTPUT_DIR=/opt/ml/output\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_NUM_CPUS=16\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_NUM_GPUS=0\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_NUM_NEURONS=0\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_MODEL_DIR=/opt/ml/model\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_MODULE_DIR=s3://sagemaker-ap-northeast-2-688554574862/test-autogluon-image-1711446762-9abf/source/sourcedir.tar.gz\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"config\":\"/opt/ml/input/data/config\",\"serving\":\"/opt/ml/input/data/serving\",\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-28c43\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[],\"current_instance_type\":\"local\",\"distribution_hosts\":[\"algo-1-28c43\"],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-28c43\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"config\":{\"TrainingInputMode\":\"File\"},\"serving\":{\"TrainingInputMode\":\"File\"},\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[],\"instance_groups_dict\":{},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"test-autogluon-image-1711446762-9abf\",\"log_level\":20,\"master_hostname\":\"algo-1-28c43\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-688554574862/test-autogluon-image-1711446762-9abf/source/sourcedir.tar.gz\",\"module_name\":\"tabular_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-28c43\",\"hosts\":[\"algo-1-28c43\"]},\"user_entry_point\":\"tabular_train.py\"}\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_USER_ARGS=[]\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_CHANNEL_CONFIG=/opt/ml/input/data/config\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_CHANNEL_TRAIN=/opt/ml/input/data/train\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_CHANNEL_TEST=/opt/ml/input/data/test\r\n",
      "u4na7hxy1w-algo-1-28c43  | SM_CHANNEL_SERVING=/opt/ml/input/data/serving\r\n",
      "u4na7hxy1w-algo-1-28c43  | PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\r\n",
      "u4na7hxy1w-algo-1-28c43  | \r\n",
      "u4na7hxy1w-algo-1-28c43  | Invoking script with the following command:\r\n",
      "u4na7hxy1w-algo-1-28c43  | \r\n",
      "u4na7hxy1w-algo-1-28c43  | /opt/conda/bin/python3.9 tabular_train.py\r\n",
      "u4na7hxy1w-algo-1-28c43  | \r\n",
      "u4na7hxy1w-algo-1-28c43  | \r\n",
      "u4na7hxy1w-algo-1-28c43  | 2024-03-26 09:52:53,369 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\r\n",
      "u4na7hxy1w-algo-1-28c43  | Starting AG\r\n",
      "u4na7hxy1w-algo-1-28c43  | Args: Namespace(output_data_dir='/opt/ml/output/data', model_dir='/opt/ml/model', n_gpus='0', train_dir='/opt/ml/input/data/train', test_dir='/opt/ml/input/data/test', ag_config='/opt/ml/input/data/config', serving_script='/opt/ml/input/data/serving')\r\n",
      "u4na7hxy1w-algo-1-28c43  | Using config-med.yaml\r\n",
      "u4na7hxy1w-algo-1-28c43  | Running training job with the config:\r\n",
      "u4na7hxy1w-algo-1-28c43  | {\r\n",
      "u4na7hxy1w-algo-1-28c43  | 'ag_fit_args': {'hyperparameters': None,\r\n",
      "u4na7hxy1w-algo-1-28c43  |                  'num_bag_folds': 2,\r\n",
      "u4na7hxy1w-algo-1-28c43  |                  'num_bag_sets': 1\r\n",
      "u4na7hxy1w-algo-1-28c43  | ,\r\n",
      "u4na7hxy1w-algo-1-28c43  |                  'num_stack_levels': 0,\r\n",
      "u4na7hxy1w-algo-1-28c43  |                  'presets': 'medium_quality_faster_train'},\r\n",
      "u4na7hxy1w-algo-1-28c43  |  'ag_predictor_args': {'eval_metric': 'roc_auc', 'label': 'class'},\r\n",
      "u4na7hxy1w-algo-1-28c43  |  'feature_importance': True,\r\n",
      "u4na7hxy1w-algo-1-28c43  |  'leaderboard': True,\r\n",
      "u4na7hxy1w-algo-1-28c43  |  'num_gpus': 0,\r\n",
      "u4na7hxy1w-algo-1-28c43  |  'output_prediction_format': 'csv'}\r\n",
      "u4na7hxy1w-algo-1-28c43  | Using train.csv\r\n",
      "u4na7hxy1w-algo-1-28c43  | Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/opt/ml/model\"\r\n",
      "u4na7hxy1w-algo-1-28c43  | Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\r\n",
      "u4na7hxy1w-algo-1-28c43  | Presets specified: ['medium_quality_faster_train']\r\n",
      "u4na7hxy1w-algo-1-28c43  | Beginning AutoGluon training ...\r\n",
      "u4na7hxy1w-algo-1-28c43  | AutoGluon will save models to \"/opt/ml/model/\"\r\n",
      "u4na7hxy1w-algo-1-28c43  | AutoGluon Version:  0.8.2\r\n",
      "u4na7hxy1w-algo-1-28c43  | Python Version:     3.9.16\r\n",
      "u4na7hxy1w-algo-1-28c43  | Operating System:   Linux\r\n",
      "u4na7hxy1w-algo-1-28c43  | Platform Machine:   x86_64\r\n",
      "u4na7hxy1w-algo-1-28c43  | Platform Version:   #1 SMP PREEMPT_DYNAMIC Fri Feb 16 11:55:08 UTC 2024\r\n",
      "u4na7hxy1w-algo-1-28c43  | Disk Space Avail:   453.04 GB / 1000.24 GB (45.3%)\r\n",
      "u4na7hxy1w-algo-1-28c43  | Train Data Rows:    32561\r\n",
      "u4na7hxy1w-algo-1-28c43  | Train Data Columns: 15\r\n",
      "u4na7hxy1w-algo-1-28c43  | Label Column: class\r\n",
      "u4na7hxy1w-algo-1-28c43  | Preprocessing data ...\r\n",
      "u4na7hxy1w-algo-1-28c43  | AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t2 unique label values:  [' <=50K', ' >50K']\r\n",
      "u4na7hxy1w-algo-1-28c43  | If 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\r\n",
      "u4na7hxy1w-algo-1-28c43  | Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\r\n",
      "u4na7hxy1w-algo-1-28c43  | \tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\r\n",
      "u4na7hxy1w-algo-1-28c43  | \tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\r\n",
      "u4na7hxy1w-algo-1-28c43  | Using Feature Generators to preprocess the data ...\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting AutoMLPipelineFeatureGenerator...\r\n",
      "u4na7hxy1w-algo-1-28c43  | Available Memory:                    15655.33 MB\r\n",
      "u4na7hxy1w-algo-1-28c43  | \tTrain Data (Original)  Memory Usage: 19.35 MB (0.1% of available memory)\r\n",
      "u4na7hxy1w-algo-1-28c43  | Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n",
      "u4na7hxy1w-algo-1-28c43  | Stage 1 Generators:\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t\tFitting AsTypeFeatureGenerator...\r\n",
      "u4na7hxy1w-algo-1-28c43  | Note: Converting 1 features to boolean dtype as they only contain 2 unique values.\r\n",
      "u4na7hxy1w-algo-1-28c43  | Stage 2 Generators:\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t\tFitting FillNaFeatureGenerator...\r\n",
      "u4na7hxy1w-algo-1-28c43  | Stage 3 Generators:\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t\tFitting IdentityFeatureGenerator...\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting CategoryFeatureGenerator...\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting CategoryMemoryMinimizeFeatureGenerator...\r\n",
      "u4na7hxy1w-algo-1-28c43  | Stage 4 Generators:\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t\tFitting DropUniqueFeatureGenerator...\r\n",
      "u4na7hxy1w-algo-1-28c43  | Stage 5 Generators:\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting DropDuplicatesFeatureGenerator...\r\n",
      "u4na7hxy1w-algo-1-28c43  | Types of features in original data (raw dtype, special dtypes):\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t\t('int', [])    : 7 | ['Unnamed: 0', 'age', 'fnlwgt', 'education-num', 'capital-gain', ...]\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\r\n",
      "u4na7hxy1w-algo-1-28c43  | Types of features in processed data (raw dtype, special dtypes):\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t\t('int', [])       : 7 | ['Unnamed: 0', 'age', 'fnlwgt', 'education-num', 'capital-gain', ...]\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t\t('int', ['bool']) : 1 | ['sex']\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t0.2s = Fit runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t15 features in original data used to generate 15 features in processed data.\r\n",
      "u4na7hxy1w-algo-1-28c43  | Train Data (Processed) Memory Usage: 2.09 MB (0.0% of available memory)\r\n",
      "u4na7hxy1w-algo-1-28c43  | Data preprocessing and feature engineering runtime = 0.25s ...\r\n",
      "u4na7hxy1w-algo-1-28c43  | AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\r\n",
      "u4na7hxy1w-algo-1-28c43  | \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\r\n",
      "u4na7hxy1w-algo-1-28c43  | \tTo change this, specify the eval_metric parameter of Predictor()\r\n",
      "u4na7hxy1w-algo-1-28c43  | User-specified model hyperparameters to be fit:\r\n",
      "u4na7hxy1w-algo-1-28c43  | {\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t'NN_TORCH': {},\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t'CAT': {},\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t'XGB': {},\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t'FASTAI': {},\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\r\n",
      "u4na7hxy1w-algo-1-28c43  | }\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting 13 L1 models ...\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting model: KNeighborsUnif_BAG_L1 ...\r\n",
      "u4na7hxy1w-algo-1-28c43  | 0.6109\t = Validation score   (roc_auc)\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t0.04s\t = Training   runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t0.12s\t = Validation runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting model: KNeighborsDist_BAG_L1 ...\r\n",
      "u4na7hxy1w-algo-1-28c43  | 0.6138\t = Validation score   (roc_auc)\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t0.04s\t = Training   runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t0.11s\t = Validation runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting model: LightGBMXT_BAG_L1 ...\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\r\n",
      "u4na7hxy1w-algo-1-28c43  | 0.9215\t = Validation score   (roc_auc)\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2.12s\t = Training   runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t0.32s\t = Validation runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting model: LightGBM_BAG_L1 ...\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\r\n",
      "u4na7hxy1w-algo-1-28c43  | 0.9263\t = Validation score   (roc_auc)\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t2.68s\t = Training   runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | 0.14s\t = Validation runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting model: RandomForestGini_BAG_L1 ...\r\n",
      "u4na7hxy1w-algo-1-28c43  | 0.9113\t = Validation score   (roc_auc)\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2.67s\t = Training   runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t1.1s\t = Validation runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting model: RandomForestEntr_BAG_L1 ...\r\n",
      "u4na7hxy1w-algo-1-28c43  | 0.9126\t = Validation score   (roc_auc)\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t2.22s\t = Training   runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | 1.09s\t = Validation runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting model: CatBoost_BAG_L1 ...\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\r\n",
      "u4na7hxy1w-algo-1-28c43  | 0.9273\t = Validation score   (roc_auc)\r\n",
      "u4na7hxy1w-algo-1-28c43  | 35.72s\t = Training   runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t0.15s\t = Validation runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting model: ExtraTreesGini_BAG_L1 ...\r\n",
      "u4na7hxy1w-algo-1-28c43  | 0.9068\t = Validation score   (roc_auc)\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t2.62s\t = Training   runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2.06s\t = Validation runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting model: ExtraTreesEntr_BAG_L1 ...\r\n",
      "u4na7hxy1w-algo-1-28c43  | 0.9065\t = Validation score   (roc_auc)\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2.32s\t = Training   runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t1.59s\t = Validation runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting model: NeuralNetFastAI_BAG_L1 ...\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\r\n",
      "u4na7hxy1w-algo-1-28c43  | 0.9105\t = Validation score   (roc_auc)\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t71.37s\t = Training   runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | 1.12s\t = Validation runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting model: XGBoost_BAG_L1 ...\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\r\n",
      "u4na7hxy1w-algo-1-28c43  | 0.9271\t = Validation score   (roc_auc)\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t37.63s\t = Training   runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t0.22s\t = Validation runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting model: NeuralNetTorch_BAG_L1 ...\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\r\n",
      "u4na7hxy1w-algo-1-28c43  | 0.9046\t = Validation score   (roc_auc)\r\n",
      "u4na7hxy1w-algo-1-28c43  | 79.25s\t = Training   runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | 0.36s\t = Validation runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting model: LightGBMLarge_BAG_L1 ...\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\r\n",
      "u4na7hxy1w-algo-1-28c43  | 0.9236\t = Validation score   (roc_auc)\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t5.06s\t = Training   runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | 0.28s\t = Validation runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | Fitting model: WeightedEnsemble_L2 ...\r\n",
      "u4na7hxy1w-algo-1-28c43  | 0.9285\t = Validation score   (roc_auc)\r\n",
      "u4na7hxy1w-algo-1-28c43  | \t8.58s\t = Training   runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | 0.01s\t = Validation runtime\r\n",
      "u4na7hxy1w-algo-1-28c43  | AutoGluon training complete, total runtime = 280.85s ... Best model: \"WeightedEnsemble_L2\"\r\n",
      "u4na7hxy1w-algo-1-28c43  | TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/opt/ml/model/\")\r\n",
      "u4na7hxy1w-algo-1-28c43  | Using test.csv\r\n",
      "u4na7hxy1w-algo-1-28c43  | Loaded data from: /opt/ml/input/data/test/test.csv | Columns = 16 / 16 | Rows = 16281 -> 16281\r\n",
      "u4na7hxy1w-algo-1-28c43  | [2024-03-26 09:57:44.735 algo-1-28c43:53 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\r\n",
      "u4na7hxy1w-algo-1-28c43  | [2024-03-26 09:57:44.787 algo-1-28c43:53 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\r\n",
      "u4na7hxy1w-algo-1-28c43  | model  score_test  score_val  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n",
      "u4na7hxy1w-algo-1-28c43  | 0       WeightedEnsemble_L2    0.928473   0.928548        1.395571       1.612886  86.823359                 0.007080                0.006046           8.582700            2       True         14\r\n",
      "u4na7hxy1w-algo-1-28c43  | 1            XGBoost_BAG_L1    0.928256   0.927139        0.219265       0.224993  37.627504                 0.219265                0.224993          37.627504            1       True         11\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2           CatBoost_BAG_L1    0.927101   0.927324        0.082571       0.152270  35.717881                 0.082571                0.152270          35.717881            1       True          7\r\n",
      "u4na7hxy1w-algo-1-28c43  | 3           LightGBM_BAG_L1    0.926434   0.926330        0.190492       0.138842   2.680208                 0.190492                0.138842           2.680208            1       True          4\r\n",
      "u4na7hxy1w-algo-1-28c43  | 4      LightGBMLarge_BAG_L1    0.925209   0.923581        0.266218       0.276907   5.059273                 0.266218                0.276907           5.059273            1       True         13\r\n",
      "u4na7hxy1w-algo-1-28c43  | 5         LightGBMXT_BAG_L1    0.921038   0.921530        0.298373       0.324444   2.123653                 0.298373                0.324444           2.123653            1       True          3\r\n",
      "u4na7hxy1w-algo-1-28c43  | 6   RandomForestEntr_BAG_L1    0.911741   0.912594        0.896163       1.090734   2.215065                 0.896163                1.090734           2.215065            1       True          6\r\n",
      "u4na7hxy1w-algo-1-28c43  | 7    NeuralNetFastAI_BAG_L1    0.911403   0.910494        2.355527       1.122681  71.373356                 2.355527                1.122681          71.373356            1       True         10\r\n",
      "u4na7hxy1w-algo-1-28c43  | 8   RandomForestGini_BAG_L1    0.910595   0.911291        0.880456       1.103033   2.671883                 0.880456                1.103033           2.671883            1       True          5\r\n",
      "u4na7hxy1w-algo-1-28c43  | 9     NeuralNetTorch_BAG_L1    0.907948   0.904553        1.195116       0.361895  79.249119                 1.195116                0.361895          79.249119            1       True         12\r\n",
      "u4na7hxy1w-algo-1-28c43  | 10    ExtraTreesGini_BAG_L1    0.905088   0.906839        1.137374       2.055776   2.621636                 1.137374                2.055776           2.621636            1       True          8\r\n",
      "u4na7hxy1w-algo-1-28c43  | 11    ExtraTreesEntr_BAG_L1    0.904993   0.906522        1.240865       1.586157   2.322568                 1.240865                1.586157           2.322568            1       True          9\r\n",
      "u4na7hxy1w-algo-1-28c43  | 12    KNeighborsUnif_BAG_L1    0.609753   0.610936        0.085284       0.119711   0.042005                 0.085284                0.119711           0.042005            1       True          1\r\n",
      "u4na7hxy1w-algo-1-28c43  | 13    KNeighborsDist_BAG_L1    0.608437   0.613812        0.085187       0.110185   0.036367                 0.085187                0.110185           0.036367            1       True          2\r\n",
      "u4na7hxy1w-algo-1-28c43  | \r\n",
      "u4na7hxy1w-algo-1-28c43  | Computing feature importance via permutation shuffling for 15 features using 5000 rows with 5 shuffle sets...\r\n",
      "u4na7hxy1w-algo-1-28c43  | 99.52s\t= Expected runtime (19.9s per shuffle set)\r\n",
      "u4na7hxy1w-algo-1-28c43  | 20.3s\t= Actual runtime (Completed 5 of 5 shuffle sets)\r\n",
      "u4na7hxy1w-algo-1-28c43  | Saving serving script\r\n",
      "u4na7hxy1w-algo-1-28c43  | Using tabular_serve.py\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2024-03-26 09:58:12,204 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2024-03-26 09:58:12,204 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\r\n",
      "u4na7hxy1w-algo-1-28c43  | 2024-03-26 09:58:12,205 sagemaker-training-toolkit INFO     Reporting training SUCCESS\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/algo-1-28c43/output/success -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/output\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/output/data\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/algo-1-28c43/output/data/feature_importance.csv -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/output/data\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/algo-1-28c43/output/data/predictions.csv -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/output/data\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/algo-1-28c43/output/data/leaderboard.csv -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/output/data\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/metadata.json -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/code\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/code/tabular_serve.py -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/code\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/predictor.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/utils\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/utils/data\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/utils/data/X.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/utils/data\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/utils/data/y.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/utils/data\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/ExtraTreesGini_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/ExtraTreesGini_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/ExtraTreesGini_BAG_L1/utils/model_template.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/ExtraTreesGini_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/ExtraTreesGini_BAG_L1/utils/oof.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/ExtraTreesGini_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/ExtraTreesGini_BAG_L1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/ExtraTreesGini_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/ExtraTreesGini_BAG_L1/S1F1\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/ExtraTreesGini_BAG_L1/S1F1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/ExtraTreesGini_BAG_L1/S1F1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u4na7hxy1w-algo-1-28c43 exited with code 0\n",
      "Aborting on container exit...\n",
      " Container u4na7hxy1w-algo-1-28c43  Stopping\n",
      " Container u4na7hxy1w-algo-1-28c43  Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/CatBoost_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/CatBoost_BAG_L1/S1F2\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/CatBoost_BAG_L1/S1F2/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/CatBoost_BAG_L1/S1F2\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/CatBoost_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/CatBoost_BAG_L1/utils/model_template.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/CatBoost_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/CatBoost_BAG_L1/utils/oof.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/CatBoost_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/CatBoost_BAG_L1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/CatBoost_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/CatBoost_BAG_L1/S1F1\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/CatBoost_BAG_L1/S1F1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/CatBoost_BAG_L1/S1F1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBMLarge_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBMLarge_BAG_L1/S1F2\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/LightGBMLarge_BAG_L1/S1F2/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBMLarge_BAG_L1/S1F2\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBMLarge_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/LightGBMLarge_BAG_L1/utils/model_template.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBMLarge_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/LightGBMLarge_BAG_L1/utils/oof.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBMLarge_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/LightGBMLarge_BAG_L1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBMLarge_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBMLarge_BAG_L1/S1F1\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/LightGBMLarge_BAG_L1/S1F1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBMLarge_BAG_L1/S1F1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/RandomForestGini_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/RandomForestGini_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/RandomForestGini_BAG_L1/utils/model_template.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/RandomForestGini_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/RandomForestGini_BAG_L1/utils/oof.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/RandomForestGini_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/RandomForestGini_BAG_L1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/RandomForestGini_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/RandomForestGini_BAG_L1/S1F1\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/RandomForestGini_BAG_L1/S1F1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/RandomForestGini_BAG_L1/S1F1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/NeuralNetFastAI_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/NeuralNetFastAI_BAG_L1/S1F2\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/NeuralNetFastAI_BAG_L1/S1F2/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/NeuralNetFastAI_BAG_L1/S1F2\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/NeuralNetFastAI_BAG_L1/S1F2/model-internals.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/NeuralNetFastAI_BAG_L1/S1F2\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/NeuralNetFastAI_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/NeuralNetFastAI_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/NeuralNetFastAI_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/NeuralNetFastAI_BAG_L1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/NeuralNetFastAI_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/NeuralNetFastAI_BAG_L1/S1F1\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/NeuralNetFastAI_BAG_L1/S1F1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/NeuralNetFastAI_BAG_L1/S1F1\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/NeuralNetFastAI_BAG_L1/S1F1/model-internals.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/NeuralNetFastAI_BAG_L1/S1F1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBM_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBM_BAG_L1/S1F2\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/LightGBM_BAG_L1/S1F2/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBM_BAG_L1/S1F2\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBM_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/LightGBM_BAG_L1/utils/model_template.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBM_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/LightGBM_BAG_L1/utils/oof.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBM_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/LightGBM_BAG_L1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBM_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBM_BAG_L1/S1F1\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/LightGBM_BAG_L1/S1F1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBM_BAG_L1/S1F1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/KNeighborsUnif_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/KNeighborsUnif_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/KNeighborsUnif_BAG_L1/utils/model_template.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/KNeighborsUnif_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/KNeighborsUnif_BAG_L1/utils/oof.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/KNeighborsUnif_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/KNeighborsUnif_BAG_L1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/KNeighborsUnif_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/KNeighborsUnif_BAG_L1/S1F1\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/KNeighborsUnif_BAG_L1/S1F1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/KNeighborsUnif_BAG_L1/S1F1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/RandomForestEntr_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/RandomForestEntr_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/RandomForestEntr_BAG_L1/utils/model_template.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/RandomForestEntr_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/RandomForestEntr_BAG_L1/utils/oof.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/RandomForestEntr_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/RandomForestEntr_BAG_L1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/RandomForestEntr_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/RandomForestEntr_BAG_L1/S1F1\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/RandomForestEntr_BAG_L1/S1F1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/RandomForestEntr_BAG_L1/S1F1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/WeightedEnsemble_L2\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/WeightedEnsemble_L2/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/WeightedEnsemble_L2/utils/model_template.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/WeightedEnsemble_L2/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/WeightedEnsemble_L2/utils/oof.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/WeightedEnsemble_L2/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/WeightedEnsemble_L2/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/WeightedEnsemble_L2\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/XGBoost_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/XGBoost_BAG_L1/S1F2\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/XGBoost_BAG_L1/S1F2/xgb.ubj -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/XGBoost_BAG_L1/S1F2\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/XGBoost_BAG_L1/S1F2/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/XGBoost_BAG_L1/S1F2\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/XGBoost_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/XGBoost_BAG_L1/utils/model_template.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/XGBoost_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/XGBoost_BAG_L1/utils/oof.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/XGBoost_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/XGBoost_BAG_L1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/XGBoost_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/XGBoost_BAG_L1/S1F1\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/XGBoost_BAG_L1/S1F1/xgb.ubj -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/XGBoost_BAG_L1/S1F1\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/XGBoost_BAG_L1/S1F1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/XGBoost_BAG_L1/S1F1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/KNeighborsDist_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/KNeighborsDist_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/KNeighborsDist_BAG_L1/utils/model_template.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/KNeighborsDist_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/KNeighborsDist_BAG_L1/utils/oof.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/KNeighborsDist_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/KNeighborsDist_BAG_L1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/KNeighborsDist_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/KNeighborsDist_BAG_L1/S1F1\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/KNeighborsDist_BAG_L1/S1F1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/KNeighborsDist_BAG_L1/S1F1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/NeuralNetTorch_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/NeuralNetTorch_BAG_L1/S1F2\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/NeuralNetTorch_BAG_L1/S1F2/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/NeuralNetTorch_BAG_L1/S1F2\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/NeuralNetTorch_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/NeuralNetTorch_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/NeuralNetTorch_BAG_L1/utils/oof.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/NeuralNetTorch_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/NeuralNetTorch_BAG_L1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/NeuralNetTorch_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/NeuralNetTorch_BAG_L1/S1F1\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/NeuralNetTorch_BAG_L1/S1F1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/NeuralNetTorch_BAG_L1/S1F1\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/trainer.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/ExtraTreesEntr_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/ExtraTreesEntr_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/ExtraTreesEntr_BAG_L1/utils/model_template.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/ExtraTreesEntr_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/ExtraTreesEntr_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/ExtraTreesEntr_BAG_L1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/ExtraTreesEntr_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/ExtraTreesEntr_BAG_L1/S1F1\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/ExtraTreesEntr_BAG_L1/S1F1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/ExtraTreesEntr_BAG_L1/S1F1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBMXT_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBMXT_BAG_L1/S1F2\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/LightGBMXT_BAG_L1/S1F2/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBMXT_BAG_L1/S1F2\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBMXT_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/LightGBMXT_BAG_L1/utils/model_template.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBMXT_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/LightGBMXT_BAG_L1/utils/oof.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBMXT_BAG_L1/utils\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/LightGBMXT_BAG_L1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBMXT_BAG_L1\n",
      "INFO:root:creating /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBMXT_BAG_L1/S1F1\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/models/LightGBMXT_BAG_L1/S1F1/model.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model/models/LightGBMXT_BAG_L1/S1F1\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/learner.pkl -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model\n",
      "INFO:root:copying /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/model/__version__ -> /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpvwf859g4/artifacts/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "job_name = utils.unique_name_from_base(\"test-autogluon-image\")\n",
    "ag.fit(\n",
    "    {\n",
    "        \"config\": config_input,\n",
    "        \"train\": train_input,\n",
    "        \"test\": eval_input,\n",
    "        \"serving\": inference_script,\n",
    "    },\n",
    "    job_name=job_name,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4d57c00",
   "metadata": {},
   "source": [
    "### Model export\n",
    "\n",
    "AutoGluon models are portable: everything needed to deploy a trained model is in the tarball created by SageMaker.\n",
    "\n",
    "The artifact can be used locally, on EC2/ECS/EKS or served via SageMaker Inference."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-northeast-2-688554574862/test-autogluon-image-1711446762-9abf/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(ag.model_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T10:05:16.025116Z",
     "start_time": "2024-03-26T10:05:16.018200Z"
    }
   },
   "id": "486077f46293e104",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1d5dccd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T10:05:22.219186Z",
     "start_time": "2024-03-26T10:05:16.018400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-ap-northeast-2-688554574862/test-autogluon-image-1711446762-9abf/model.tar.gz to ./model.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {ag.model_data} ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b240c86b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-26T10:05:22.424222Z",
     "start_time": "2024-03-26T10:05:22.224256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 elnath  staff  180148384 Mar 26 19:05 model.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls -alF model.tar.gz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7633d597",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Endpoint Deployment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb4fb9ec",
   "metadata": {},
   "source": [
    "Upload the model we trained earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "90f6eaa2",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-26T10:05:27.317878Z",
     "start_time": "2024-03-26T10:05:22.418023Z"
    }
   },
   "outputs": [],
   "source": [
    "endpoint_name = sagemaker.utils.unique_name_from_base(\"sagemaker-autogluon-serving-trained-model\")\n",
    "\n",
    "model_data = sagemaker_session.upload_data(\n",
    "    path=os.path.join(\".\", \"model.tar.gz\"), key_prefix=f\"{endpoint_name}/models\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4c9a075",
   "metadata": {},
   "source": [
    "Deploy remote or local endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8fa6dd02",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-26T10:05:27.321936Z",
     "start_time": "2024-03-26T10:05:27.317889Z"
    }
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.m5.2xlarge\"\n",
    "# instance_type = 'local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae49533e",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-26T10:05:27.479044Z",
     "start_time": "2024-03-26T10:05:27.318101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/elnath/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "model = AutoGluonNonRepackInferenceModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    region=region,\n",
    "    framework_version=\"0.8\",\n",
    "    py_version=\"py39\",\n",
    "    instance_type=instance_type,\n",
    "    source_dir=\"scripts\",\n",
    "    entry_point=\"tabular_serve.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7e333d24",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-26T10:08:59.572825Z",
     "start_time": "2024-03-26T10:05:27.417921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/elnath/Library/Application Support/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: autogluon-inference-2024-03-26-10-05-27-585\n",
      "INFO:sagemaker:Creating endpoint-config with name autogluon-inference-2024-03-26-10-05-28-264\n",
      "INFO:sagemaker:Creating endpoint with name autogluon-inference-2024-03-26-10-05-28-264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "model.deploy(initial_instance_count=1, serializer=CSVSerializer(), instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autogluon-inference-2024-03-26-10-05-28-264\n"
     ]
    }
   ],
   "source": [
    "print(model.endpoint_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T10:08:59.579505Z",
     "start_time": "2024-03-26T10:08:59.574153Z"
    }
   },
   "id": "5a1d909654069cc",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "30190a41-71df-4eca-a616-a32ee9b5b50a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T10:08:59.918454Z",
     "start_time": "2024-03-26T10:08:59.584035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/elnath/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "predictor = AutoGluonRealtimePredictor(model.endpoint_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52982b98",
   "metadata": {},
   "source": [
    "### Predict on unlabeled test data\n",
    "\n",
    "Remove target variable (`class`) from the data and get predictions for a sample of 100 rows using the deployed endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "85e3fab4",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-26T10:22:33.096622Z",
     "start_time": "2024-03-26T10:22:33.043225Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/test.csv\")\n",
    "data = df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c61ab16a",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-26T10:22:34.592547Z",
     "start_time": "2024-03-26T10:22:33.643034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      pred   <=50K_proba   >50K_proba\n0    <=50K      0.998020     0.001980\n1    <=50K      0.817559     0.182441\n2    <=50K      0.677092     0.322908\n3     >50K      0.012731     0.987269\n4    <=50K      0.999618     0.000382\n..     ...           ...          ...\n95   <=50K      0.999205     0.000795\n96   <=50K      0.989381     0.010619\n97   <=50K      0.918478     0.081522\n98   <=50K      0.649154     0.350846\n99   <=50K      0.998852     0.001148\n\n[100 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pred</th>\n      <th>&lt;=50K_proba</th>\n      <th>&gt;50K_proba</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;=50K</td>\n      <td>0.998020</td>\n      <td>0.001980</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;=50K</td>\n      <td>0.817559</td>\n      <td>0.182441</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;=50K</td>\n      <td>0.677092</td>\n      <td>0.322908</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&gt;50K</td>\n      <td>0.012731</td>\n      <td>0.987269</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;=50K</td>\n      <td>0.999618</td>\n      <td>0.000382</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>&lt;=50K</td>\n      <td>0.999205</td>\n      <td>0.000795</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>&lt;=50K</td>\n      <td>0.989381</td>\n      <td>0.010619</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>&lt;=50K</td>\n      <td>0.918478</td>\n      <td>0.081522</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>&lt;=50K</td>\n      <td>0.649154</td>\n      <td>0.350846</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>&lt;=50K</td>\n      <td>0.998852</td>\n      <td>0.001148</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = predictor.predict(data.drop(columns=\"class\"))\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2f7a8ab4",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-26T10:22:35.689188Z",
     "start_time": "2024-03-26T10:22:35.644391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     pred  actual\n0   <=50K   <=50K\n1   <=50K   <=50K\n2   <=50K    >50K\n3    >50K    >50K\n4   <=50K   <=50K",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pred</th>\n      <th>actual</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;=50K</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;=50K</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;=50K</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&gt;50K</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;=50K</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = preds[[\"pred\"]]\n",
    "p = p.join(data[\"class\"]).rename(columns={\"class\": \"actual\"})\n",
    "p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a9d9dcbe",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-26T10:22:36.569330Z",
     "start_time": "2024-03-26T10:22:36.530892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/100 are correct\n"
     ]
    }
   ],
   "source": [
    "print(f\"{(p.pred==p.actual).astype(int).sum()}/{len(p)} are correct\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "084ee65e",
   "metadata": {},
   "source": [
    "### Cleanup Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cdd315e3",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-26T10:22:51.270966Z",
     "start_time": "2024-03-26T10:22:50.780309Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: autogluon-inference-2024-03-26-10-05-28-264\n",
      "INFO:sagemaker:Deleting endpoint with name: autogluon-inference-2024-03-26-10-05-28-264\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8197080",
   "metadata": {},
   "source": [
    "# Batch Transform\n",
    "\n",
    "Deploying a trained model to a hosted endpoint has been available in SageMaker since launch and is a great way to provide real-time predictions to a service like a website or mobile app. But, if the goal is to generate predictions from a trained model on a large dataset where minimizing latency isn’t a concern, then the batch transform functionality may be easier, more scalable, and more appropriate.\n",
    "\n",
    "[Read more about Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4b607438",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-26T10:23:14.946336Z",
     "start_time": "2024-03-26T10:23:09.198083Z"
    }
   },
   "outputs": [],
   "source": [
    "endpoint_name = sagemaker.utils.unique_name_from_base(\n",
    "    \"sagemaker-autogluon-batch_transform-trained-model\"\n",
    ")\n",
    "\n",
    "model_data = sagemaker_session.upload_data(\n",
    "    path=os.path.join(\".\", \"model.tar.gz\"), key_prefix=f\"{endpoint_name}/models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab078513",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-26T10:23:14.950766Z",
     "start_time": "2024-03-26T10:23:14.943207Z"
    }
   },
   "outputs": [],
   "source": [
    "# instance_type = \"ml.m5.2xlarge\"\n",
    "instance_type = \"local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c88630d4",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-26T10:23:14.984782Z",
     "start_time": "2024-03-26T10:23:14.948599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/elnath/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "model = AutoGluonSagemakerInferenceModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    region=region,\n",
    "    framework_version=\"0.8\",\n",
    "    py_version=\"py39\",\n",
    "    instance_type=instance_type,\n",
    "    entry_point=\"tabular_serve-batch.py\",\n",
    "    source_dir=\"scripts\",\n",
    "    predictor_cls=AutoGluonBatchPredictor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "276fd30b",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-26T10:29:30.903712Z",
     "start_time": "2024-03-26T10:23:14.982434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/elnath/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/elnath/Library/Application Support/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-ap-northeast-2-688554574862/sagemaker-autogluon-batch_transform-trained-mod-1711448589-ea65/models/model.tar.gz), script artifact (scripts), and dependencies ([]) into single tar.gz file located at s3://sagemaker-ap-northeast-2-688554574862/autogluon-inference-2024-03-26-10-23-14-985/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: autogluon-inference-2024-03-26-10-29-30-887\n"
     ]
    }
   ],
   "source": [
    "transformer = model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    strategy=\"MultiRecord\",\n",
    "    max_payload=6,\n",
    "    max_concurrent_transforms=1,\n",
    "    output_path=output_path,\n",
    "    accept=\"application/json\",\n",
    "    assemble_with=\"Line\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9559625",
   "metadata": {},
   "source": [
    "Prepare data for batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a8dde772",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-26T10:29:30.939511Z",
     "start_time": "2024-03-26T10:29:30.897274Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv(f\"data/test.csv\")[:100].to_csv(\"data/test_no_header.csv\", header=False, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "355fabc8",
   "metadata": {},
   "source": [
    "Upload data to sagemaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eb3dbd00",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-26T10:29:31.090660Z",
     "start_time": "2024-03-26T10:29:30.936631Z"
    }
   },
   "outputs": [],
   "source": [
    "test_input = transformer.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"data\", \"test_no_header.csv\"), key_prefix=s3_prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b21b56f5",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-26T10:38:23.278323Z",
     "start_time": "2024-03-26T10:29:31.091617Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: autogluon-inference-2024-03-26-10-29-31-090\n",
      "INFO:sagemaker.local.image:'Docker Compose' found using Docker CLI.\n",
      "INFO:sagemaker.local.image:serving\n",
      "INFO:sagemaker.local.image:creating hosting dir in /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpdugnb5hx\n",
      "INFO:sagemaker.local.image:docker command: docker pull 763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/autogluon-inference:0.8-cpu-py39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "What's Next?\n",
      "  View a summary of image vulnerabilities and recommendations → docker scout quickview 763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/autogluon-inference:0.8-cpu-py39\n",
      "INFO:sagemaker.local.image:image pulled: 763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/autogluon-inference:0.8-cpu-py39\n",
      "INFO:sagemaker.local.image:Using the long-lived AWS credentials found in session\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-bzve4:\n",
      "    command: serve\n",
      "    container_name: sgs8u17efu-algo-1-bzve4\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: 763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/autogluon-inference:0.8-cpu-py39\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-bzve4\n",
      "    ports:\n",
      "    - 8080:8080\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpbcc_385m:/opt/ml/model\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker compose -f /private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpdugnb5hx/docker-compose.yaml up --build --abort-on-container-exit\n",
      "INFO:sagemaker.local.entities:Checking if serving container is up, attempt: 5\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1a7b6d040>: Failed to establish a new connection: [Errno 61] Connection refused')': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1a7b6d340>: Failed to establish a new connection: [Errno 61] Connection refused')': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1a7b6dc40>: Failed to establish a new connection: [Errno 61] Connection refused')': /ping\n",
      "INFO:sagemaker.local.entities:Container still not up, got: -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to sgs8u17efu-algo-1-bzve4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.local.entities:Checking if serving container is up, attempt: 10\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))': /ping\n",
      "INFO:sagemaker.local.entities:Container still not up, got: -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgs8u17efu-algo-1-bzve4  | ['torchserve', '--start', '--model-store', '/.sagemaker/ts/models', '--ts-config', '/etc/sagemaker-ts.properties', '--log-config', '/opt/conda/lib/python3.9/site-packages/sagemaker_pytorch_serving_container/etc/log4j2.xml', '--models', 'model=/opt/ml/model']\r\n",
      "sgs8u17efu-algo-1-bzve4  | Warning: TorchServe is using non-default JVM parameters: -XX:-UseContainerSupport\r\n",
      "sgs8u17efu-algo-1-bzve4  | WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:21,492 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:21,773 [INFO ] main org.pytorch.serve.ModelServer - \r\n",
      "sgs8u17efu-algo-1-bzve4  | Torchserve version: 0.7.1\r\n",
      "sgs8u17efu-algo-1-bzve4  | TS Home: /opt/conda/lib/python3.9/site-packages\r\n",
      "sgs8u17efu-algo-1-bzve4  | Current directory: /\r\n",
      "sgs8u17efu-algo-1-bzve4  | Temp directory: /home/model-server/tmp\r\n",
      "sgs8u17efu-algo-1-bzve4  | Metrics config path: /opt/conda/lib/python3.9/site-packages/ts/configs/metrics.yaml\r\n",
      "sgs8u17efu-algo-1-bzve4  | Number of GPUs: 0\r\n",
      "sgs8u17efu-algo-1-bzve4  | Number of CPUs: 16\r\n",
      "sgs8u17efu-algo-1-bzve4  | Max heap size: 4000 M\r\n",
      "sgs8u17efu-algo-1-bzve4  | Python executable: /opt/conda/bin/python3.9\r\n",
      "sgs8u17efu-algo-1-bzve4  | Config file: /etc/sagemaker-ts.properties\r\n",
      "sgs8u17efu-algo-1-bzve4  | Inference address: http://0.0.0.0:8080\r\n",
      "sgs8u17efu-algo-1-bzve4  | Management address: http://0.0.0.0:8080\r\n",
      "sgs8u17efu-algo-1-bzve4  | Metrics address: http://127.0.0.1:8082\r\n",
      "sgs8u17efu-algo-1-bzve4  | Model Store: /.sagemaker/ts/models\r\n",
      "sgs8u17efu-algo-1-bzve4  | Initial Models: model=/opt/ml/model\r\n",
      "sgs8u17efu-algo-1-bzve4  | Log dir: /logs\r\n",
      "sgs8u17efu-algo-1-bzve4  | Metrics dir: /logs\r\n",
      "sgs8u17efu-algo-1-bzve4  | Netty threads: 0\r\n",
      "sgs8u17efu-algo-1-bzve4  | Netty client threads: 0\r\n",
      "sgs8u17efu-algo-1-bzve4  | Default workers per model: 16\r\n",
      "sgs8u17efu-algo-1-bzve4  | Blacklist Regex: N/A\r\n",
      "sgs8u17efu-algo-1-bzve4  | Maximum Response Size: 6553500\r\n",
      "sgs8u17efu-algo-1-bzve4  | Maximum Request Size: 6553500\r\n",
      "sgs8u17efu-algo-1-bzve4  | Limit Maximum Image Pixels: true\r\n",
      "sgs8u17efu-algo-1-bzve4  | Prefer direct buffer: false\r\n",
      "sgs8u17efu-algo-1-bzve4  | Allowed Urls: [file://.*|http(s)?://.*]\r\n",
      "sgs8u17efu-algo-1-bzve4  | Custom python dependency for model allowed: false\r\n",
      "sgs8u17efu-algo-1-bzve4  | Metrics report format: prometheus\r\n",
      "sgs8u17efu-algo-1-bzve4  | Enable metrics API: true\r\n",
      "sgs8u17efu-algo-1-bzve4  | Workflow Store: /.sagemaker/ts/models\r\n",
      "sgs8u17efu-algo-1-bzve4  | Model config: N/A\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:21,794 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:21,858 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: /opt/ml/model\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:21,868 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive version is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:21,869 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive createdOn is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:21,873 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:21,945 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.local.entities:Checking if serving container is up, attempt: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:22,301 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:22,304 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:22,313 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:22,958 [INFO ] pool-2-thread-17 ACCESS_LOG - /192.168.65.1:25108 \"GET /ping HTTP/1.1\" 200 66\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:22,970 [INFO ] pool-2-thread-17 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:04f042b04f1c,timestamp:1711449442\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:23,701 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /192.168.65.1:25109 \"GET /execution-parameters HTTP/1.1\" 404 8\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:23,712 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:04f042b04f1c,timestamp:1711449442\r\n",
      "sgs8u17efu-algo-1-bzve4  | Model server started.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:24,717 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:25,496 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:04f042b04f1c,timestamp:1711449445\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:25,504 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:142.16153717041016|#Level:Host|#hostname:04f042b04f1c,timestamp:1711449445\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:25,506 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:80.26968383789062|#Level:Host|#hostname:04f042b04f1c,timestamp:1711449445\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:25,511 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:36.1|#Level:Host|#hostname:04f042b04f1c,timestamp:1711449445\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:25,520 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:14254.48828125|#Level:Host|#hostname:04f042b04f1c,timestamp:1711449445\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:25,521 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1406.65234375|#Level:Host|#hostname:04f042b04f1c,timestamp:1711449445\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:25,529 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:10.9|#Level:Host|#hostname:04f042b04f1c,timestamp:1711449445\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:33,596 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:33,654 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.9/site-packages/ts/configs/metrics.yaml.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:33,659 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]81\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:33,661 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:33,664 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.9.13\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:33,735 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:33,819 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:33,828 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1711449453828\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:33,870 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9011\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:33,971 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.9/site-packages/ts/configs/metrics.yaml.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:33,977 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - [PID]97\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:33,998 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Torch worker started.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,003 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,022 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Python runtime: 3.9.13\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,063 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9006\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,081 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.9/site-packages/ts/configs/metrics.yaml.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,064 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,082 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - [PID]99\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,091 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Torch worker started.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,105 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Python runtime: 3.9.13\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,093 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,142 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9011.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,194 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1711449454194\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,500 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9012\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,504 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9014\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,504 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.9/site-packages/ts/configs/metrics.yaml.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,506 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - [PID]100\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,507 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Torch worker started.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,507 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Python runtime: 3.9.13\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,510 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.9/site-packages/ts/configs/metrics.yaml.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,513 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - [PID]101\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,519 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1711449454519\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,521 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,523 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9006.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,526 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Torch worker started.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,528 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Python runtime: 3.9.13\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,800 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9005\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,800 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9007\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,516 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,807 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,809 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.9/site-packages/ts/configs/metrics.yaml.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,810 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - [PID]85\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,811 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Torch worker started.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,812 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Python runtime: 3.9.13\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,815 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.9/site-packages/ts/configs/metrics.yaml.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,817 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - [PID]87\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,817 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Torch worker started.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,817 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,819 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.9/site-packages/ts/configs/metrics.yaml.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,819 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]83\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,820 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,820 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.9.13\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:35,041 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,821 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:35,048 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:34,818 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Python runtime: 3.9.13\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:35,079 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:35,086 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1711449455086\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:35,083 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9014.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:35,075 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:35,575 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1711449455575\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:35,950 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1711449455950\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:35,575 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9013\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:35,975 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:35,978 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.9/site-packages/ts/configs/metrics.yaml.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:35,979 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - [PID]102\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:35,980 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Torch worker started.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:35,980 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Python runtime: 3.9.13\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:35,825 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9007.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:35,824 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.9/site-packages/ts/configs/metrics.yaml.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:35,969 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9009\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:35,987 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]82\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:35,969 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9004\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:35,989 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1711449455989\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:35,992 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,001 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.9/site-packages/ts/configs/metrics.yaml.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,014 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - [PID]95\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,016 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Torch worker started.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,018 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Python runtime: 3.9.13\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,006 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9012.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,030 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.9/site-packages/ts/configs/metrics.yaml.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,004 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.9.13\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,031 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - [PID]80\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,092 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Torch worker started.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,097 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Python runtime: 3.9.13\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,113 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,118 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,121 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,512 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9010\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,514 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.9/site-packages/ts/configs/metrics.yaml.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,515 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - [PID]96\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,516 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Torch worker started.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,517 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Python runtime: 3.9.13\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,521 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,520 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9008\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,855 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9015\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,857 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.9/site-packages/ts/configs/metrics.yaml.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,857 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - [PID]88\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,512 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:37,293 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Torch worker started.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:37,296 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.9/site-packages/ts/configs/metrics.yaml.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:37,297 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - [PID]98\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:37,297 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Torch worker started.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:37,390 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:37,398 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Python runtime: 3.9.13\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:37,358 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,522 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:37,294 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Python runtime: 3.9.13\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:37,280 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:36,864 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:38,256 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.9/site-packages/ts/configs/metrics.yaml.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:38,256 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]103\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:38,257 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:38,257 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.9.13\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:38,264 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1711449458263\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:38,353 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:38,354 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9005.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:38,424 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:38,675 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:38,697 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:38,721 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1711449458721\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:38,748 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1711449458748\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:38,749 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9009.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:38,752 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:39,039 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9008.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:39,043 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1711449459043\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:39,042 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9015.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:39,449 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:39,451 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9010.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:39,470 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9013.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:39,474 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1711449459474\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:39,678 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9004.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:39,678 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1711449459678\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:39,807 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:39,807 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1711449459807\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:39,439 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1711449459439\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:40,027 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:40,044 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:40,055 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1711449460054\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:40,060 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:40,807 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:41,311 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:41,316 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:41,321 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:49,720 [WARN ] W-9003-model_1.0-stderr MODEL_LOG - Found 1 mismatches between original and current metadata:\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:49,724 [WARN ] W-9003-model_1.0-stderr MODEL_LOG - \tINFO: AutoGluon Python micro version mismatch (original=3.9.16, current=3.9.13)\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:50,017 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15927\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:50,056 [INFO ] W-9003-model_1.0 TS_METRICS - W-9003-model_1.0.ms:28159|#Level:Host|#hostname:04f042b04f1c,timestamp:1711449470\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:50,061 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.ms:306|#Level:Host|#hostname:04f042b04f1c,timestamp:1711449470\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:50,073 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1711449470072\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:50,092 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1711449470\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:50,189 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:96.33|#ModelName:model,Level:Model|#hostname:04f042b04f1c,requestID:ec1a4be4-dba2-4822-9e5a-088f6e173446,timestamp:1711449470\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:50,195 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 101\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:50,197 [INFO ] W-9003-model_1.0 ACCESS_LOG - /192.168.65.1:25110 \"POST /invocations HTTP/1.1\" 500 25560\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:50,198 [INFO ] W-9003-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:04f042b04f1c,timestamp:1711449442\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:50,207 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.ms:25316|#Level:Host|#hostname:04f042b04f1c,timestamp:1711449470\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:50,208 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.ms:35|#Level:Host|#hostname:04f042b04f1c,timestamp:1711449470\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:51,388 [WARN ] W-9014-model_1.0-stderr MODEL_LOG - Found 1 mismatches between original and current metadata:\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:51,404 [WARN ] W-9014-model_1.0-stderr MODEL_LOG - \tINFO: AutoGluon Python micro version mismatch (original=3.9.16, current=3.9.13)\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:51,434 [WARN ] W-9011-model_1.0-stderr MODEL_LOG - Found 1 mismatches between original and current metadata:\r\n",
      "sgs8u17efu-algo-1-bzve4  | 2024-03-26T10:37:51,437 [WARN ] W-9011-model_1.0-stderr MODEL_LOG - \tINFO: AutoGluon Python micro version mismatch (original=3.9.16, current=3.9.13)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/elnath/anaconda3/envs/venv_sagemaker_39/lib/python3.9/site-packages/sagemaker/local/image.py\", line 918, in run\n",
      "    _stream_output(self.process)\n",
      "  File \"/Users/elnath/anaconda3/envs/venv_sagemaker_39/lib/python3.9/site-packages/sagemaker/local/image.py\", line 984, in _stream_output\n",
      "    raise RuntimeError(\"Process exited with code: %s\" % exit_code)\n",
      "RuntimeError: Process exited with code: 130\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/elnath/anaconda3/envs/venv_sagemaker_39/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/elnath/anaconda3/envs/venv_sagemaker_39/lib/python3.9/site-packages/sagemaker/local/image.py\", line 923, in run\n",
      "    raise RuntimeError(msg)\n",
      "RuntimeError: Failed to run: ['docker', 'compose', '-f', '/private/var/folders/yp/836q9b2x1_n1fm3627j48ssc0000gn/T/tmpdugnb5hx/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    }
   ],
   "source": [
    "transformer.transform(\n",
    "    test_input,\n",
    "    input_filter=\"$[:14]\",  # filter-out target variable\n",
    "    split_type=\"Line\",\n",
    "    content_type=\"text/csv\",\n",
    "    output_filter=\"$['class']\",  # keep only prediction class in the output\n",
    ")\n",
    "\n",
    "transformer.wait()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee44ccfb",
   "metadata": {},
   "source": [
    "Download batch transform outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e07ff698",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-26T10:38:25.305325Z",
     "start_time": "2024-03-26T10:38:23.266317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal error: An error occurred (404) when calling the HeadObject operation: Key \"autogluon_sm/2024-03-26-09-52-40-076/output/test_no_header.csv.out\" does not exist\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {transformer.output_path[:-1]}/test_no_header.csv.out ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ac3b0953",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-26T10:38:25.492158Z",
     "start_time": "2024-03-26T10:38:25.331315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    preds  actual\n0   <=50K   <=50K\n1   <=50K   <=50K\n2   <=50K    >50K\n3    >50K    >50K\n4   <=50K   <=50K",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>preds</th>\n      <th>actual</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;=50K</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;=50K</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;=50K</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&gt;50K</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;=50K</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pd.concat(\n",
    "    [\n",
    "        pd.read_json(\"test_no_header.csv.out\", orient=\"index\")\n",
    "        .sort_index()\n",
    "        .rename(columns={0: \"preds\"}),\n",
    "        pd.read_csv(\"data/test.csv\")[[\"class\"]].iloc[:100].rename(columns={\"class\": \"actual\"}),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7150fa02",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-26T10:38:25.497276Z",
     "start_time": "2024-03-26T10:38:25.450144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/100 are correct\n"
     ]
    }
   ],
   "source": [
    "print(f\"{(p.preds==p.actual).astype(int).sum()}/{len(p)} are correct\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd3e9e5a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "In this tutorial we successfully trained an AutoGluon model and explored a few options how to deploy it using SageMaker. Any of the sections of this tutorial (training/endpoint inference/batch inference) can be used independently (i.e. train locally, deploy to SageMaker, or vice versa).\n",
    "\n",
    "Next steps:\n",
    "* [Learn more](https://auto.gluon.ai) about AutoGluon, explore [tutorials](https://auto.gluon.ai/stable/tutorials/index.html).\n",
    "* Explore [SageMaker inference documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html)."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "name": "venv_sagemaker_39",
   "language": "python",
   "display_name": "venv_sagemaker_39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
